{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A1. Data Preprocessing – Hospital Data\n",
    "\n",
    "**Description**  \n",
    "This section preprocesses hospital-level data from the American Hospital Association (AHA) dataset.  \n",
    "It includes steps such as data loading, filtering, recoding, and cleaning to prepare the dataset for analysis of hospital characteristics.\n",
    "\n",
    "**Data Source**  \n",
    "- American Hospital Association (AHA) Annual Survey and IT Supplement (Year: 2023)  \n",
    "- Catherine E Strawley, Julia Adler-Milstein, A Jay Holmgren, Jordan Everson, New indices to track interoperability among US hospitals, Journal of the American Medical Informatics Association, Volume 32, Issue 2, February 2025, Pages 318–327\n",
    "\n",
    "**Purpose**  \n",
    "To create a cleaned, analysis-ready dataset that supports downstream tasks\n",
    "\n",
    "**Disclaimer**  \n",
    "This codebase was partially cleaned and annotated using OpenAI’s ChatGPT-4o.  \n",
    "Please review and validate before using for critical applications.\n",
    "\n",
    "**notebook workflow** \n",
    "1. load necessary libraries\n",
    "2. load AHA annual survey data \n",
    "3. load AHA hospital geocodes \n",
    "4. load AHA IT data \n",
    "5. create master dataframe linking annual survey and IT data \n",
    "6. calculate interoperability features \n",
    "7. save master dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. load necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load libraries \n",
    "# Import standard Python libraries\n",
    "import getpass  \n",
    "import re \n",
    "import json \n",
    "import sys  \n",
    "\n",
    "# Import data analysis and visualization libraries\n",
    "import pandas as pd \n",
    "import numpy as np  \n",
    "import seaborn as sns  \n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "# Import datetime utilities\n",
    "from datetime import datetime, timedelta  \n",
    "\n",
    "\n",
    "# Import operating system utilities\n",
    "import os  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. load annual survey data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path to the AHA dataset (last 5 years)\n",
    "AHA_AS_path = \"../../../data/AHA/AHA_recent5yrs.csv\"\n",
    "\n",
    "# Load the dataset into a DataFrame\n",
    "AHA_AS_df = pd.read_csv(AHA_AS_path, low_memory=False)\n",
    "\n",
    "# Subset the data to include only records from the year 2023\n",
    "AHA2023 = AHA_AS_df[AHA_AS_df.YEAR == 2023]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. load geocodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path to the geocoded AHA address dataset\n",
    "AHA_address_path = \"../../../data/AHA/AHA_address_geocode.csv\"\n",
    "\n",
    "# Load the address dataset\n",
    "AHA_address_df = pd.read_csv(AHA_address_path, low_memory=False)\n",
    "\n",
    "# Keep only the columns needed for geospatial merging\n",
    "AHA_address_df = AHA_address_df[['ID', 'latitude_address', 'longitude_address']]\n",
    "\n",
    "# Count hospitals missing both latitude and longitude\n",
    "missing_geocodes = AHA_address_df[\n",
    "    (AHA_address_df['latitude_address'].isnull()) | \n",
    "    (AHA_address_df['longitude_address'].isnull())\n",
    "].shape[0]\n",
    "\n",
    "print(f\"Total of {missing_geocodes} hospitals with missing geocodes (either latitude and longitude)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. load IT data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path to the 2023 AHA IT Supplement dataset\n",
    "AHA_IT_path = \"../../../data/AHA/2023AHAIT.csv\"\n",
    "\n",
    "# Load the IT dataset\n",
    "AHA_IT_df = pd.read_csv(AHA_IT_path, low_memory=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. create master dataframe linking annual survey, geocodes, and IT data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Standardize ID columns by converting to string and removing whitespace\n",
    "AHA2023['ID'] = AHA2023['ID'].astype(str).str.replace(r\"\\s+\", \"\", regex=True)\n",
    "AHA_address_df['ID'] = AHA_address_df['ID'].astype(str).str.replace(r\"\\s+\", \"\", regex=True)\n",
    "AHA_IT_df['id'] = AHA_IT_df['id'].astype(str).str.replace(r\"\\s+\", \"\", regex=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 standardize column names for annnual survey data \n",
    "\n",
    "# Make a copy of the original AHA2023 DataFrame\n",
    "AHA2023_2 = AHA2023.copy()\n",
    "\n",
    "\n",
    "# Rename columns: lowercase + `_as` suffix to indicate Annual Survey source\n",
    "AHA2023_2.columns = [col.lower() + '_as' for col in AHA2023_2.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3 standardize column names for IT data \n",
    "\n",
    "# Make a copy of the AHA IT dataset\n",
    "AHA_IT_2 = AHA_IT_df.copy()\n",
    "\n",
    "# Rename columns: lowercase + `_it` suffix to indicate IT Supplement source\n",
    "AHA_IT_2.columns = [col.lower() + '_it' for col in AHA_IT_2.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5.4 Merge AHA Annual Survey, IT Supplement, and Address Data\n",
    "\n",
    "# This step merges:\n",
    "# 1. AHA Annual Survey (`AHA2023_2`) with the IT Supplement (`AHA_IT_2`) using hospital ID.\n",
    "# 2. The result with geocoded address data (`AHA_address_df`), again using hospital ID.\n",
    "\n",
    "# The merged dataset is used for further analysis. The original `ID` column from the address file is dropped to avoid redundancy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge AHA Annual Survey with IT Supplement data\n",
    "AHA_AS_IT_joined = AHA2023_2.merge(AHA_IT_2, left_on='id_as', right_on='id_it', how='left')\n",
    "\n",
    "# Merge with geocoded address data\n",
    "AHA_AS_IT_address_joined = AHA_address_df.merge(AHA_AS_IT_joined, left_on='ID', right_on='id_as', how='left')\n",
    "\n",
    "# Check the shape of the merged dataset\n",
    "AHA_AS_IT_address_joined.shape\n",
    "\n",
    "# Drop redundant ID column from address data\n",
    "AHA_AS_IT_address_joined = AHA_AS_IT_address_joined.drop('ID', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the functions\n",
    "AHA_AS_IT_address_joined['core_index'] = AHA_AS_IT_address_joined.apply(calculate_interoperability.calculate_core_index, axis=1)\n",
    "AHA_AS_IT_address_joined['friction_index'] = AHA_AS_IT_address_joined.apply(calculate_interoperability.calculate_friction_index, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.5 Save the final merged dataset to CSV (excluding the index column)\n",
    "AHA_AS_IT_address_joined.to_csv('./data/AHA2023_master.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
