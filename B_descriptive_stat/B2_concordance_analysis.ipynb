{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B2. Concordance Analysis â€“ Need vs AI Implementation\n",
    "\n",
    "**Description**  \n",
    "This section evaluates the alignment between healthcare need and AI implementation levels across hospitals. Tertiles are computed for both variables to assess patterns of concordance.\n",
    "\n",
    "**Purpose**  \n",
    "To examine whether AI implementation levels correspond with areas of greatest need. High concordance would suggest equitable distribution, while misalignment could indicate disparities in AI resource allocation.\n",
    "\n",
    "**Method Summary**  \n",
    "- Rank-based tertiles were created for HPSA, MUA, ADI, SVI scores.  \n",
    "- AI implementation scores were already categorized into tertiles (Low, Medium, High).  \n",
    "- Cross-tabulations were generated and visualized using heatmaps.  \n",
    "- A \"perfect concordance rate\" was calculated as the percentage of hospitals where AI implementation and need tertiles matched exactly (diagonal cells).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 1 Load necessary libraries, functions, and pre-processed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load necessary libraries \n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_exposures = [\"ai_base_score\",\n",
    "\"ai_base_breadth_score\",\n",
    "\"ai_base_dev_score\",\n",
    "\"ai_base_eval_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "AHA_master = pd.read_csv(\"./data/AHA_master_external_data.csv\", low_memory=False)\n",
    "AHA_IT = AHA_master[AHA_master.id_it.notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Data engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AHA_master2 = calculate_ai_scores.apply_ai_scores_to_dataframe(AHA_IT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AHA_IT_US = AHA_master2[AHA_master2['division']!='Territories']\n",
    "AHA_IT_US.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numeric AI implementation scores to categorical labels\n",
    "AHA_IT_US['AI_implementation_tertile'] = AHA_IT_US['ai_base_score'].map({\n",
    "    0: 'Low',\n",
    "    1: 'Medium',\n",
    "    2: 'High'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Concordance analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create tertiles for all need measures using rank-based approach\n",
    "\n",
    "# HPSA measures\n",
    "AHA_IT_US['primary_hpss_tertile'] = pd.qcut(AHA_IT_US['mean_primary_hpss'].rank(method='first'), \n",
    "                                           3, \n",
    "                                           labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "AHA_IT_US['mental_hpss_tertile'] = pd.qcut(AHA_IT_US['mean_mental_hpss'].rank(method='first'), \n",
    "                                          3, \n",
    "                                          labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "AHA_IT_US['dental_hpss_tertile'] = pd.qcut(AHA_IT_US['mean_dental_hpss'].rank(method='first'), \n",
    "                                          3, \n",
    "                                          labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "# MUA measures\n",
    "AHA_IT_US['mua_score_tertile'] = pd.qcut(AHA_IT_US['mean_mua_score'].rank(method='first'), \n",
    "                                        3, \n",
    "                                        labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "# Add MUA-specific measures (elder and infant)\n",
    "AHA_IT_US['mua_elder_tertile'] = pd.qcut(AHA_IT_US['mean_mua_elders_score'].rank(method='first'), \n",
    "                                        3, \n",
    "                                        labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "AHA_IT_US['mua_infant_tertile'] = pd.qcut(AHA_IT_US['mean_mua_infant_score'].rank(method='first'), \n",
    "                                         3, \n",
    "                                         labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "# Area Deprivation Index (higher score = higher need)\n",
    "AHA_IT_US['adi_tertile'] = pd.qcut(AHA_IT_US['national_adi_median'].rank(method='first'), \n",
    "                                  3, \n",
    "                                  labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "# Social Vulnerability Index (higher score = higher need)\n",
    "AHA_IT_US['svi_tertile'] = pd.qcut(AHA_IT_US['svi_themes_median'].rank(method='first'), \n",
    "                                  3, \n",
    "                                  labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "# Convert numeric AI implementation scores to categorical labels\n",
    "AHA_IT_US['AI_implementation_tertile'] = AHA_IT_US['ai_base_score'].map({\n",
    "    0: 'Low',\n",
    "    1: 'Medium',\n",
    "    2: 'High'\n",
    "})\n",
    "\n",
    "# Convert to categorical type with ordered categories\n",
    "AHA_IT_US['AI_implementation_tertile'] = pd.Categorical(\n",
    "    AHA_IT_US['AI_implementation_tertile'],\n",
    "    categories=['Low', 'Medium', 'High'],\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Create concordance tables for all measures\n",
    "need_measures = {\n",
    "    # Top row - HPSA measures\n",
    "    'Primary HPSA': 'primary_hpss_tertile',\n",
    "    'Mental HPSA': 'mental_hpss_tertile', \n",
    "    'Dental HPSA': 'dental_hpss_tertile',\n",
    "    # Middle row - MUA measures\n",
    "    'MUA Overall': 'mua_score_tertile',\n",
    "    'MUA Elder': 'mua_elder_tertile',\n",
    "    'MUA Infant': 'mua_infant_tertile',\n",
    "    # Bottom row - Social indices\n",
    "    'Area Deprivation Index': 'adi_tertile',\n",
    "    'Social Vulnerability Index': 'svi_tertile',\n",
    "    'Empty': None  # Placeholder for 3x3 grid\n",
    "}\n",
    "\n",
    "concordance_tables = {}\n",
    "for name, column in need_measures.items():\n",
    "    if column is not None:  # Skip the empty placeholder\n",
    "        concordance_tables[name] = pd.crosstab(\n",
    "            AHA_IT_US[column], \n",
    "            AHA_IT_US['AI_implementation_tertile'], \n",
    "            normalize=True\n",
    "        ) * 100\n",
    "        # Reorder to put High Need at TOP, Low Need at BOTTOM\n",
    "        concordance_tables[name] = concordance_tables[name].reindex(['High', 'Medium', 'Low'])\n",
    "\n",
    "# Create 3x3 visualization\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "\n",
    "# Calculate global min and max for uniform color scale\n",
    "all_values = []\n",
    "for table in concordance_tables.values():\n",
    "    all_values.extend(table.values.flatten())\n",
    "vmin = min(all_values)\n",
    "vmax = max(all_values)\n",
    "\n",
    "lat_order = [\n",
    "    'Primary HPSA', 'Mental HPSA', 'Dental HPSA',        # Top row - HPSA\n",
    "    'MUA Overall', 'MUA Elder', 'MUA Infant',            # Middle row - MUA  \n",
    "    'Area Deprivation Index', 'Social Vulnerability Index', 'Empty'  # Bottom row - Social indices\n",
    "]\n",
    "\n",
    "# Plot all concordance heatmaps\n",
    "for i, name in enumerate(lat_order):\n",
    "    row = i // 3\n",
    "    col = i % 3\n",
    "    \n",
    "    if name == 'Empty':\n",
    "        # Hide the empty subplot\n",
    "        axes[row, col].axis('off')\n",
    "    else:\n",
    "        table = concordance_tables[name]\n",
    "        sns.heatmap(table, \n",
    "                    annot=True, \n",
    "                    fmt='.1f', \n",
    "                    cmap='YlOrRd', \n",
    "                    ax=axes[row, col],\n",
    "                    vmin=vmin, vmax=vmax,  # Uniform color scale\n",
    "                    cbar_kws={'label': 'Percentage'})\n",
    "        axes[row, col].set_title(f'{name} vs AI Implementation')\n",
    "        axes[row, col].set_xlabel('AI Implementation Level')\n",
    "        axes[row, col].set_ylabel(f'{name} Need Level')\n",
    "        \n",
    "\n",
    "plt.tight_lat()\n",
    "plt.show()\n",
    "\n",
    "# Display all concordance tables\n",
    "for name, table in concordance_tables.items():\n",
    "    print(f\"\\n{name} Need Level vs AI Implementation\")\n",
    "    print(table)\n",
    "\n",
    "# Calculate mismatch percentages for all measures\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MISMATCH PERCENTAGES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for name, table in concordance_tables.items():\n",
    "    # Calculate ideal concordance (diagonal cells)\n",
    "    ideal_concordance = (table.iloc[0, 2] +  # High Need + High AI\n",
    "                        table.iloc[1, 1] +   # Medium Need + Medium AI\n",
    "                        table.iloc[2, 0])    # Low Need + Low AI\n",
    "    \n",
    "    # Calculate mismatch percentage\n",
    "    mismatch_percentage = 100 - ideal_concordance\n",
    "    \n",
    "    print(f\"{name}: {mismatch_percentage:.2f}% mismatch\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
