{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D1. Feature importance analysis \n",
    "\n",
    "**Description**  \n",
    "This section conducts machine learning (random forest) to identify the most important feature predicting the AI/ML implementation level \n",
    "\n",
    "**Purpose**  \n",
    "To identify the most important feature predicting the AI/ML implementation level \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Load necessary libraries, functions, and pre-processed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning and model evaluation\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    classification_report,\n",
    "    r2_score, \n",
    "    mean_squared_error, \n",
    "    mean_absolute_error,\n",
    "    mean_absolute_percentage_error\n",
    ")\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load preprocessed dataframe \n",
    "AHA_master = pd.read_csv('./data/AHA_master_external_data.csv', low_memory=False)\n",
    "AHA_IT = AHA_master[~AHA_master['id_it'].isnull()]\n",
    "AHA_IT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import and if needed, reload the module\n",
    "import calculate_ai_scores\n",
    "AHA_master2 = calculate_ai_scores.apply_ai_scores_to_dataframe(AHA_IT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Data engineering \n",
    "\n",
    "These hospital characteristics were selected based on investigator consensus, and we used LASSO regression analysis to explore and identify additional variables that predict AI/ML implementation and reflect hospital resource levels.\n",
    "\n",
    "- **rural_urban_type** : collected from AHA survey. categorized into {1: rural, 2: micro, 3: metro} based on the location of the hospital ('CBSATYPE')\n",
    "- **system member** : hospital belonging to a corporate body that owns or manage health provider facilities or health-related subsidiaries. ('MHSMEMB')\n",
    "- **delivery_system** : delivery system identified using existing theory and AHA Annual Survey data {1: Centralized Health System, 2: Centralized Physician/Insurance Health System, 3: Moderately Centralized Health System, 4: Decentralized Health System, 5: Independent Hospital System, 6/Missing: Insufficient data to determine} ('CLUSTER')\n",
    "- **community_hospital** : all nonfederal, short-term general, and special hospitals whose facilities and services are available to the public {0: No, 1: Yes}('CHC')\n",
    "- **subsidary_hospital** : Hospital itself operates subsidiary corporation {0: No, 1: Yes} ('SUBS')\n",
    "- **frontline_hospital** : Frontline facility {0: No, 1: Yes} ('FRTLN')\n",
    "- **joint_commission_accreditaion** : Accreditation by joint commision {0: No, 1: Yes} ('MAPP1')\n",
    "- **center_quality** : Center for Improvement in Healthcare Quality Accreditation {0: No, 1: Yes} ('MAPP22')\n",
    "- **teaching_hospital** : major teaching hospital ('MAPP8'), minor teaching hospital ('MAPP3' or 'MAPP5')\n",
    "- **critical_access** critical access hospital {0: No, 1: Yes} ('MAPP18')\n",
    "- **rural_referral** : rural referral center {0: No, 1: Yes} ('MAPP19')\n",
    "- **ownership_type** : type of organization responsible for establishing policy concerning overall operation {government_federal, government_nonfederal, nonprofit, forprofit, other} ('CNTRL')\n",
    "- **bedsize** : bed-size category, ordinal variable ('BSC')\n",
    "- **medicare_ipd_percentage** : medicare inpatient days / total inpatient days. Proxy variable to reflect the proportion of medicare patient \n",
    "- **medicaid_ipd_percentage** : medicaid inpatient days / total inpatient days. Proxy variable to reflect the proportion of medicaid patients \n",
    "- **core_index** : summary measure to track the interoperability of US hospitals (https://doi.org/10.1093/jamia/ocae289)\n",
    "- **friction_index** : summary measures to track the barrier or difficulty in interoperability between hospitals (https://doi.org/10.1093/jamia/ocae289)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rural_urban_type\n",
    "# Continue with CBSA type and other variables\n",
    "AHA_master2['rural_urban_type'] = AHA_master2['cbsatype_as'].map({\n",
    "    'Rural': 1,      # Rural = 1 (lowest)\n",
    "    'Micro': 2,      # Micropolitan = 2 (middle)\n",
    "    'Metro': 3       # Metropolitan = 3 (highest)\n",
    "})\n",
    "\n",
    "## system_member\n",
    "# Create new column 'system_member' based on the conditions\n",
    "AHA_master2['system_member'] = AHA_master2['mhsmemb_as'].copy()\n",
    "# Set to 1 where sysid_as is not null and mhsmemb_as is null\n",
    "AHA_master2.loc[(AHA_master2['sysid_as'].notna()) & (AHA_master2['mhsmemb_as'].isna()), 'system_member'] = 1\n",
    "# Convert all remaining null values to 0\n",
    "AHA_master2['system_member'] = AHA_master2['system_member'].fillna(0)\n",
    "\n",
    "## AHA System Cluster Code - delivery_system\n",
    "AHA_master2['delivery_system'] = AHA_master2['cluster_as']\n",
    "\n",
    "## community_hospital\n",
    "AHA_master2['community_hospital'] = AHA_master2['chc_as'].replace(2, 0)\n",
    "\n",
    "## subsidary_hospital\n",
    "AHA_master2['subsidary_hospital'] = AHA_master2['subs_as']\n",
    "\n",
    "## frontline_hospital\n",
    "AHA_master2['frontline_hospital'] = AHA_master2['frtln_as'].replace('.', 0)\n",
    "\n",
    "## joint_commission_accreditation\n",
    "AHA_master2['joint_commission_accreditation'] = AHA_master2['mapp1_as'].replace(2,0)\n",
    "\n",
    "## center_quality\n",
    "AHA_master2['center_quality'] = AHA_master2['mapp22_as'].replace(2,0)\n",
    "\n",
    "# teaching hospitals \n",
    "AHA_master2['teaching_hospital'] = ((AHA_master2['mapp5_as'] == 1) | (AHA_master2['mapp3_as'] == 1) | (AHA_master2['mapp8_as'] == 1)).astype(int)\n",
    "AHA_master2['major_teaching_hospital'] = ((AHA_master2['mapp8_as'] == 1)).astype(int)\n",
    "AHA_master2['minor_teaching_hospital'] = (((AHA_master2['mapp5_as'] == 1) | (AHA_master2['mapp3_as'] == 1))&~(AHA_master2['mapp8_as'] == 1)).astype(int)\n",
    "\n",
    "# critical access hospital\n",
    "AHA_master2['critical_access'] = (AHA_master2['mapp18_as'] == 1).astype(int)\n",
    "\n",
    "\n",
    "# rural referral center \n",
    "AHA_master2['rural_referral'] = (AHA_master2['mapp19_as'] == 1).astype(int)\n",
    "\n",
    "# medicare medicaid percentage\n",
    "AHA_master2['medicare_ipd_percentage'] = AHA_master2['mcripd_as'] / AHA_master2['ipdtot_as'] * 100\n",
    "AHA_master2['medicaid_ipd_percentage'] = AHA_master2['mcdipd_as'] / AHA_master2['ipdtot_as'] * 100\n",
    "\n",
    "# bed size \n",
    "AHA_master2['bedsize'] = AHA_master2['bsc_as'].astype(int)\n",
    "\n",
    "# hospital ownership type \n",
    "\n",
    "AHA_master2['nonfederal_governement'] = ((AHA_master2['cntrl_as'] == 12) | (AHA_master2['cntrl_as'] == 13)|(AHA_master['cntrl_as'] == 14) | (AHA_master['cntrl_as'] == 15)| (AHA_master['cntrl_as'] == 16)).astype(int)\n",
    "AHA_master2['non_profit_nongovernment'] = ((AHA_master2['cntrl_as'] == 21) | (AHA_master2['cntrl_as'] == 23)).astype(int)\n",
    "AHA_master2['for_profit'] = ((AHA_master2['cntrl_as'] == 31) | (AHA_master2['cntrl_as'] == 32) | (AHA_master['cntrl_as'] == 33)).astype(int)\n",
    "AHA_master2['federal_government'] = ((AHA_master2['cntrl_as'] == 40) | (AHA_master2['cntrl_as'] == 44) | (AHA_master2['cntrl_as'] == 45) | (AHA_master2['cntrl_as'] == 46) | (AHA_master['cntrl_as'] == 47) | (AHA_master['cntrl_as'] == 48)).astype(int)\n",
    "# Create a categorical column for hospital ownership types\n",
    "def create_ownership_category(row):\n",
    "    if row['cntrl_as'] in [12, 13, 14, 15, 16]:\n",
    "        return 'nonfederal_government'\n",
    "    elif row['cntrl_as'] in [21, 23]:\n",
    "        return 'non_profit_nongovernment'\n",
    "    elif row['cntrl_as'] in [31, 32, 33]:\n",
    "        return 'for_profit'\n",
    "    elif row['cntrl_as'] in [40, 44, 45, 46, 47, 48]:\n",
    "        return 'federal_government'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "# Create the categorical column\n",
    "AHA_master2['ownership_type'] = AHA_master2.apply(create_ownership_category, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_features = [\"teaching_hospital\",\n",
    "\"nonfederal_governement\",\n",
    "\"non_profit_nongovernment\",\n",
    "\"for_profit\",\n",
    "\"federal_government\",\n",
    "\"critical_access\",\n",
    "\"rural_referral\",\n",
    "\"medicare_ipd_percentage\",\n",
    "\"medicaid_ipd_percentage\",\n",
    "\"bedsize\",\n",
    "\"delivery_system\",\n",
    "\"community_hospital\",\n",
    "\"subsidary_hospital\",\n",
    "\"frontline_hospital\",\n",
    "\"joint_commission_accreditation\",\n",
    "\"center_quality\",\n",
    "\"system_member\"]\n",
    "coordinates_features = [\"latitude_address\",\n",
    "\"longitude_address\"]\n",
    "geo_features = [\"rural_urban_type\",\n",
    "\"national_adi_median\",\n",
    "\"svi_themes_median\",\n",
    "\"svi_theme1_median\",\n",
    "\"svi_theme2_median\",\n",
    "\"svi_theme3_median\",\n",
    "\"svi_theme4_median\",\n",
    "\"Device_Percent\",\n",
    "\"Broadband_Percent\",\n",
    "\"Internet_Percent\",\n",
    "\"mean_primary_hpss\",\n",
    "\"mean_dental_hpss\",\n",
    "\"mean_mental_hpss\",\n",
    "\"mean_mua_score\",\n",
    "\"mean_mua_elders_score\",\n",
    "\"mean_mua_infant_score\"]\n",
    "interoperability_features = ['core_index', \"friction_index\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = hospital_features + geo_features + interoperability_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AHA_master2[\"ai_base_score\"] = AHA_master2[\"ai_base_score\"].astype(float).fillna(0)\n",
    "y = AHA_master2['ai_base_score'].values  # Replace this with  actual target column\n",
    "X = AHA_master2[feature_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize cross-validation\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "r2_scores = []\n",
    "rmse_scores = []\n",
    "mae_scores = []\n",
    "mape_scores = []\n",
    "feature_importances = []\n",
    "\n",
    "print(\"Starting cross-validation with Random Forest feature importance...\")\n",
    "\n",
    "# Perform cross-validation with proper scaling\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):\n",
    "    print(f\"Processing fold {fold}/{n_splits}...\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    # CORRECTED: Fit scaler on training data only\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = pd.DataFrame(\n",
    "        scaler.fit_transform(X_train), \n",
    "        columns=X.columns,\n",
    "        index=X_train.index\n",
    "    )\n",
    "    X_val_scaled = pd.DataFrame(\n",
    "        scaler.transform(X_val), \n",
    "        columns=X.columns,\n",
    "        index=X_val.index\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "\n",
    "    feature_importances.append(rf_model.feature_importances_)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = rf_model.predict(X_val_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    r2_scores.append(r2_score(y_val, y_pred))\n",
    "    rmse_scores.append(np.sqrt(mean_squared_error(y_val, y_pred)))\n",
    "    mae_scores.append(mean_absolute_error(y_val, y_pred))\n",
    "    mape_scores.append(mean_absolute_percentage_error(y_val, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Calculate average feature importance across folds\n",
    "avg_feature_importance = np.mean(feature_importances, axis=0)\n",
    "std_feature_importance = np.std(feature_importances, axis=0)\n",
    "\n",
    "# Create feature importance DataFrame\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': avg_feature_importance,\n",
    "    'std_importance': std_feature_importance,\n",
    "    'cv_stability': 1 - (std_feature_importance / (avg_feature_importance + 1e-10))  # Stability metric\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "# Print cross-validation results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL PERFORMANCE METRICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"R² Score: {np.mean(r2_scores):.4f} (±{np.std(r2_scores):.4f})\")\n",
    "print(f\"Root Mean Squared Error: {np.mean(rmse_scores):.4f} (±{np.std(rmse_scores):.4f})\")\n",
    "print(f\"Mean Absolute Error: {np.mean(mae_scores):.4f} (±{np.std(mae_scores):.4f})\")\n",
    "print(f\"Mean Absolute Percentage Error: {np.mean(mape_scores)*100:.2f}% (±{np.std(mape_scores)*100:.2f}%)\")\n",
    "\n",
    "# Print top 10 most important features with their standard deviations\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"TOP 10 MOST IMPORTANT FEATURES\")\n",
    "print(\"=\"*60)\n",
    "print(\"Note: Using Random Forest built-in feature importance (Gini importance)\")\n",
    "top_10 = feature_importance.head(10)[['feature', 'importance', 'std_importance', 'cv_stability']]\n",
    "print(top_10.to_string(index=False, float_format='%.4f'))\n",
    "\n",
    "# Create the figure with specific size and DPI\n",
    "fig, ax = plt.subplots(figsize=(10, 8), dpi=300)\n",
    "\n",
    "# Create the horizontal bar plot\n",
    "feature_importance_plot = feature_importance.head(10)\n",
    "bars = ax.barh(feature_importance_plot['feature'], \n",
    "               feature_importance_plot['importance'],\n",
    "               xerr=feature_importance_plot['std_importance'],\n",
    "               capsize=5,\n",
    "               color='#2E86C1',  # Professional blue color\n",
    "               alpha=0.8,\n",
    "               edgecolor='black',\n",
    "               linewidth=0.5)\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_xlabel('Feature Importance (Gini Importance)', fontweight='bold', labelpad=10)\n",
    "ax.set_title('Top 10 Most Important Features', fontweight='bold', pad=20)\n",
    "\n",
    "\n",
    "# Adjust lat\n",
    "plt.tight_lat()\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_shap_plot_cv_approach(X, y, n_folds=5, title='SHAP Feature Importance for AI Base Score'):\n",
    "    \"\"\"\n",
    "    Create SHAP plot using cross-validation approach for more robust results\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import KFold\n",
    "    \n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    all_shap_values = []\n",
    "    all_X_scaled = []\n",
    "    \n",
    "    # Collect SHAP values from multiple CV folds\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "        print(f\"Processing fold {fold+1}/{n_folds} for SHAP...\")\n",
    "        \n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # Proper scaling within fold\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X.columns)\n",
    "        X_val_scaled = pd.DataFrame(scaler.transform(X_val), columns=X.columns)\n",
    "        \n",
    "        # Train model\n",
    "        model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Calculate SHAP values for validation set\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        shap_values = explainer.shap_values(X_val_scaled)\n",
    "        \n",
    "        all_shap_values.append(shap_values)\n",
    "        all_X_scaled.append(X_val_scaled)\n",
    "    \n",
    "    # Combine all SHAP values and features\n",
    "    combined_shap = np.vstack(all_shap_values)\n",
    "    combined_X = pd.concat(all_X_scaled, ignore_index=True)\n",
    "    \n",
    "   \n",
    "    plt.figure(figsize=(12, 8), dpi=300)\n",
    "    shap.summary_plot(combined_shap, combined_X, show=False, max_display=10)\n",
    "    \n",
    "    # Customize\n",
    "    plt.title(title, fontweight='bold', pad=20, fontsize=16)\n",
    "    ax = plt.gca()\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    plt.tight_lat()\n",
    "    plt.show()\n",
    "    \n",
    "    return combined_shap, combined_X\n",
    "\n",
    "shap_values, X_combined = create_shap_plot_cv_approach(X, y, n_folds=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
