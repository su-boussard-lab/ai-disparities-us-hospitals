{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C5. Geographically Weighted Regression \n",
    "\n",
    "**Description**  \n",
    "This section conducts geographically weighted regression between hosptial/community characteristics and AI implementation level\n",
    "\n",
    "**Purpose**  \n",
    "To model and analyze spatial relationships between hosptial/community characteristics and AI implementation level \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Load necessary libraries, functions, and pre-processed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import contextily as ctx\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load preprocessed dataframe \n",
    "AHA_master = pd.read_csv('./data/AHA_master_external_data.csv', low_memory=False)\n",
    "AHA_IT = AHA_master[~AHA_master['id_it'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SHAPE_RESTORE_SHX'] = 'YES'\n",
    "states = gpd.read_file('../../../data/map_data/state_boundary.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "AHA_master2 = apply_ai_scores_to_dataframe(AHA_IT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Data engineering \n",
    "\n",
    "These hospital characteristics were selected based on investigator consensus, and we used LASSO regression analysis to explore and identify additional variables that predict AI/ML implementation and reflect hospital resource levels.\n",
    "\n",
    "- **rural_urban_type** : collected from AHA survey. categorized into {1: rural, 2: micro, 3: metro} based on the location of the hospital ('CBSATYPE')\n",
    "- **system member** : hospital belonging to a corporate body that owns or manage health provider facilities or health-related subsidiaries. ('MHSMEMB')\n",
    "- **delivery_system** : delivery system identified using existing theory and AHA Annual Survey data {1: Centralized Health System, 2: Centralized Physician/Insurance Health System, 3: Moderately Centralized Health System, 4: Decentralized Health System, 5: Independent Hospital System, 6/Missing: Insufficient data to determine} ('CLUSTER')\n",
    "- **community_hospital** : all nonfederal, short-term general, and special hospitals whose facilities and services are available to the public {0: No, 1: Yes}('CHC')\n",
    "- **subsidary_hospital** : Hospital itself operates subsidiary corporation {0: No, 1: Yes} ('SUBS')\n",
    "- **frontline_hospital** : Frontline facility {0: No, 1: Yes} ('FRTLN')\n",
    "- **joint_commission_accreditaion** : Accreditation by joint commision {0: No, 1: Yes} ('MAPP1')\n",
    "- **center_quality** : Center for Improvement in Healthcare Quality Accreditation {0: No, 1: Yes} ('MAPP22')\n",
    "- **teaching_hospital** : major teaching hospital ('MAPP8'), minor teaching hospital ('MAPP3' or 'MAPP5')\n",
    "- **critical_access** critical access hospital {0: No, 1: Yes} ('MAPP18')\n",
    "- **rural_referral** : rural referral center {0: No, 1: Yes} ('MAPP19')\n",
    "- **ownership_type** : type of organization responsible for establishing policy concerning overall operation {government_federal, government_nonfederal, nonprofit, forprofit, other} ('CNTRL')\n",
    "- **bedsize** : bed-size category, ordinal variable ('BSC')\n",
    "- **medicare_ipd_percentage** : medicare inpatient days / total inpatient days. Proxy variable to reflect the proportion of medicare patient \n",
    "- **medicaid_ipd_percentage** : medicaid inpatient days / total inpatient days. Proxy variable to reflect the proportion of medicaid patients \n",
    "- **core_index** : summary measure to track the interoperability of US hospitals (https://doi.org/10.1093/jamia/ocae289)\n",
    "- **friction_index** : summary measures to track the barrier or difficulty in interoperability between hospitals (https://doi.org/10.1093/jamia/ocae289)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rural_urban_type\n",
    "# Continue with CBSA type and other variables\n",
    "AHA_master2['rural_urban_type'] = AHA_master2['cbsatype_as'].map({\n",
    "    'Rural': 1,      # Rural = 1 (lowest)\n",
    "    'Micro': 2,      # Micropolitan = 2 (middle)\n",
    "    'Metro': 3       # Metropolitan = 3 (highest)\n",
    "})\n",
    "\n",
    "## system_member\n",
    "# Create new column 'system_member' based on the conditions\n",
    "AHA_master2['system_member'] = AHA_master2['mhsmemb_as'].copy()\n",
    "# Set to 1 where sysid_as is not null and mhsmemb_as is null\n",
    "AHA_master2.loc[(AHA_master2['sysid_as'].notna()) & (AHA_master2['mhsmemb_as'].isna()), 'system_member'] = 1\n",
    "# Convert all remaining null values to 0\n",
    "AHA_master2['system_member'] = AHA_master2['system_member'].fillna(0)\n",
    "\n",
    "## AHA System Cluster Code - delivery_system\n",
    "AHA_master2['delivery_system'] = AHA_master2['cluster_as']\n",
    "\n",
    "## community_hospital\n",
    "AHA_master2['community_hospital'] = AHA_master2['chc_as'].replace(2, 0)\n",
    "\n",
    "## subsidary_hospital\n",
    "AHA_master2['subsidary_hospital'] = AHA_master2['subs_as']\n",
    "\n",
    "## frontline_hospital\n",
    "AHA_master2['frontline_hospital'] = AHA_master2['frtln_as'].replace('.', 0)\n",
    "\n",
    "## joint_commission_accreditation\n",
    "AHA_master2['joint_commission_accreditation'] = AHA_master2['mapp1_as'].replace(2,0)\n",
    "\n",
    "## center_quality\n",
    "AHA_master2['center_quality'] = AHA_master2['mapp22_as'].replace(2,0)\n",
    "\n",
    "# teaching hospitals \n",
    "AHA_master2['teaching_hospital'] = ((AHA_master2['mapp5_as'] == 1) | (AHA_master2['mapp3_as'] == 1) | (AHA_master2['mapp8_as'] == 1)).astype(int)\n",
    "AHA_master2['major_teaching_hospital'] = ((AHA_master2['mapp8_as'] == 1)).astype(int)\n",
    "AHA_master2['minor_teaching_hospital'] = (((AHA_master2['mapp5_as'] == 1) | (AHA_master2['mapp3_as'] == 1))&~(AHA_master2['mapp8_as'] == 1)).astype(int)\n",
    "\n",
    "# critical access hospital\n",
    "AHA_master2['critical_access'] = (AHA_master2['mapp18_as'] == 1).astype(int)\n",
    "\n",
    "\n",
    "# rural referral center \n",
    "AHA_master2['rural_referral'] = (AHA_master2['mapp19_as'] == 1).astype(int)\n",
    "\n",
    "# medicare medicaid percentage\n",
    "AHA_master2['medicare_ipd_percentage'] = AHA_master2['mcripd_as'] / AHA_master2['ipdtot_as'] * 100\n",
    "AHA_master2['medicaid_ipd_percentage'] = AHA_master2['mcdipd_as'] / AHA_master2['ipdtot_as'] * 100\n",
    "\n",
    "# bed size \n",
    "AHA_master2['bedsize'] = AHA_master2['bsc_as'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hospital ownership type \n",
    "\n",
    "AHA_master2['nonfederal_governement'] = ((AHA_master2['cntrl_as'] == 12) | (AHA_master2['cntrl_as'] == 13)|(AHA_master['cntrl_as'] == 14) | (AHA_master['cntrl_as'] == 15)| (AHA_master['cntrl_as'] == 16)).astype(int)\n",
    "AHA_master2['non_profit_nongovernment'] = ((AHA_master2['cntrl_as'] == 21) | (AHA_master2['cntrl_as'] == 23)).astype(int)\n",
    "AHA_master2['for_profit'] = ((AHA_master2['cntrl_as'] == 31) | (AHA_master2['cntrl_as'] == 32) | (AHA_master['cntrl_as'] == 33)).astype(int)\n",
    "AHA_master2['federal_governement'] = ((AHA_master2['cntrl_as'] == 40) | (AHA_master2['cntrl_as'] == 44) | (AHA_master2['cntrl_as'] == 45) | (AHA_master2['cntrl_as'] == 46) | (AHA_master['cntrl_as'] == 47) | (AHA_master['cntrl_as'] == 48)).astype(int)\n",
    "# Create a categorical column for hospital ownership types\n",
    "def create_ownership_category(row):\n",
    "    if row['cntrl_as'] in [12, 13, 14, 15, 16]:\n",
    "        return 'nonfederal_government'\n",
    "    elif row['cntrl_as'] in [21, 23]:\n",
    "        return 'non_profit_nongovernment'\n",
    "    elif row['cntrl_as'] in [31, 32, 33]:\n",
    "        return 'for_profit'\n",
    "    elif row['cntrl_as'] in [40, 44, 45, 46, 47, 48]:\n",
    "        return 'federal_government'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "# Create the categorical column\n",
    "AHA_master2['ownership_type'] = AHA_master2.apply(create_ownership_category, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_hospitals = AHA_master2.dropna(subset=['long_as', 'lat_as', 'ai_base_score'])\n",
    "valid_geo_hospitals = AHA_master2.dropna(subset=['long_as', 'lat_as'])\n",
    "# Create a GeoDataFrame\n",
    "hospitals_gdf = gpd.GeoDataFrame(\n",
    "    valid_hospitals, \n",
    "    geometry=gpd.points_from_xy(valid_hospitals.long_as, valid_hospitals.lat_as),\n",
    "    crs=\"EPSG:4326\" #geographic coordinate system using latitude and longitude\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's check what we have in valid_hospitals\n",
    "print(\"\\nChecking valid_hospitals:\")\n",
    "print(f\"valid_hospitals exists: {'valid_hospitals' in locals()}\")\n",
    "if 'valid_hospitals' in locals():\n",
    "    print(f\"valid_hospitals shape: {valid_hospitals.shape}\")\n",
    "    print(\"\\nFirst few rows of valid_hospitals:\")\n",
    "    print(valid_hospitals.head())\n",
    "    print(\"\\nColumns in valid_hospitals:\")\n",
    "    print(valid_hospitals.columns.tolist())\n",
    "    print(\"\\nData types of columns:\")\n",
    "    print(valid_hospitals.dtypes)\n",
    "    print(\"\\nMissing values in each column:\")\n",
    "    print(valid_hospitals.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Run GWR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Prepare coordinates and target variable\n",
    "coords = np.array(valid_hospitals[['long_as', 'lat_as']])\n",
    "y = valid_hospitals['ai_base_score'].values\n",
    "    \n",
    "# 2. Prepare feature matrix (same as  original code)\n",
    "print(\"Preparing feature matrix...\")\n",
    "X_data = pd.DataFrame(index=valid_hospitals.index)\n",
    "    \n",
    "# Hospital characteristics missing value imputation \n",
    "X_data['subsidary_hospital'] = valid_hospitals['subsidary_hospital'].fillna(0)\n",
    "X_data['frontline_hospital'] = valid_hospitals['frontline_hospital'].fillna(0)\n",
    "X_data['joint_commission_accreditation'] = valid_hospitals['joint_commission_accreditation'].astype(float).fillna(0)\n",
    "X_data['delivery_system'] = valid_hospitals['delivery_system'].astype(float).fillna(0)\n",
    "X_data['teaching_hospital'] = valid_hospitals['teaching_hospital'].astype(float)\n",
    "X_data['critical_access'] = valid_hospitals['critical_access'].astype(float)\n",
    "X_data['rural_referral'] = valid_hospitals['rural_referral'].astype(float)\n",
    "X_data['for_profit'] = (valid_hospitals['ownership_type'] == 'for_profit').astype(float)\n",
    "X_data['bedsize'] = valid_hospitals['bedsize'].astype(float).fillna(valid_hospitals['bedsize'].median())\n",
    "X_data['medicare_ipd_percentage'] = valid_hospitals['medicare_ipd_percentage'].astype(float).fillna(valid_hospitals['medicare_ipd_percentage'].median())\n",
    "X_data['medicaid_ipd_percentage'] = valid_hospitals['medicaid_ipd_percentage'].astype(float).fillna(valid_hospitals['medicaid_ipd_percentage'].median())\n",
    "X_data['core_index'] = valid_hospitals['core_index'].astype(float).fillna(valid_hospitals['core_index'].median())\n",
    "X_data['friction_index'] = valid_hospitals['friction_index'].astype(float).fillna(valid_hospitals['friction_index'].median())\n",
    "    \n",
    "# Standardize continuous variables (except binary variables)\n",
    "continuous_vars = ['delivery_system', 'bedsize', 'medicare_ipd_percentage', 'medicaid_ipd_percentage', \n",
    "                      'core_index', 'friction_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_gwr_robust(coords, y, X, bandwidth):\n",
    "    \"\"\"Simple GWR with numerical stability\"\"\"\n",
    "    n = len(coords)\n",
    "    p = X.shape[1]\n",
    "    results = np.zeros((n, p))\n",
    "    \n",
    "    for i in range(n):\n",
    "        # Calculate distances\n",
    "        dists = np.sqrt(np.sum((coords - coords[i])**2, axis=1))\n",
    "        \n",
    "        # Calculate Gaussian weights\n",
    "        weights = np.exp(-0.5 * (dists / bandwidth)**2)\n",
    "        \n",
    "        # Filter observations with meaningful weights\n",
    "        threshold = 0.001\n",
    "        mask = weights >= threshold\n",
    "        \n",
    "        if np.sum(mask) <= p:  # Need p+1 observations minimum\n",
    "            results[i] = np.nan\n",
    "            continue\n",
    "        \n",
    "        # Subset data\n",
    "        X_local = X[mask]\n",
    "        y_local = y[mask]\n",
    "        w_local = weights[mask]\n",
    "        \n",
    "        # Proper weighted least squares\n",
    "        W = np.diag(np.sqrt(w_local))  # Square root for correct weighting\n",
    "        XW = W @ X_local\n",
    "        yW = W @ y_local\n",
    "        \n",
    "        # Normal equations\n",
    "        XtWX = XW.T @ XW\n",
    "        XtWy = XW.T @ yW\n",
    "        \n",
    "        # Add regularization if needed\n",
    "        reg_param = 1e-6 * np.trace(XtWX) / p\n",
    "        XtWX_reg = XtWX + reg_param * np.eye(p)\n",
    "        \n",
    "        try:\n",
    "            beta = np.linalg.solve(XtWX_reg, XtWy)\n",
    "            results[i] = beta\n",
    "        except np.linalg.LinAlgError:\n",
    "            results[i] = np.nan\n",
    "    \n",
    "    return results\n",
    "\n",
    "def run_gwr(X_data, y, coords, continuous_vars, bandwidth):\n",
    "    \"\"\"Complete GWR workflow with data preparation\"\"\"\n",
    "    \n",
    "    # Prepare data\n",
    "    X_processed = X_data.copy()\n",
    "    \n",
    "    # Standardize continuous variables\n",
    "    if continuous_vars:\n",
    "        scaler = StandardScaler()\n",
    "        X_processed[continuous_vars] = scaler.fit_transform(X_data[continuous_vars])\n",
    "    else:\n",
    "        scaler = None\n",
    "    \n",
    "    # Add intercept\n",
    "    X_processed['const'] = 1.0\n",
    "    \n",
    "    # Convert to array\n",
    "    X_array = X_processed.values.astype(float)\n",
    "    \n",
    "    # Run GWR\n",
    "    print(f\"Running GWR with bandwidth: {bandwidth:.3f}\")\n",
    "    final_params = simple_gwr_robust(coords, y, X_array, bandwidth)\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    results_df = pd.DataFrame()\n",
    "    \n",
    "    # Add coefficients (exclude intercept from main results)\n",
    "    for i, col in enumerate(X_processed.columns):\n",
    "        if col != 'const':\n",
    "            results_df[f'{col}_coeff'] = final_params[:, i]\n",
    "    \n",
    "    # Add intercept separately\n",
    "    const_idx = list(X_processed.columns).index('const')\n",
    "    results_df['intercept'] = final_params[:, const_idx]\n",
    "    \n",
    "    # Add coordinates\n",
    "    results_df['longitude'] = coords[:, 0]\n",
    "    results_df['latitude'] = coords[:, 1]\n",
    "    \n",
    "    # Summary statistics\n",
    "    total_valid = np.sum(np.all(np.isfinite(final_params), axis=1))\n",
    "    total_obs = len(coords)\n",
    "    \n",
    "    print(f\"Results Summary:\")\n",
    "    print(f\"  Valid observations: {total_valid}/{total_obs} ({100*total_valid/total_obs:.1f}%)\")\n",
    "    \n",
    "    # Variable summaries\n",
    "    for col in X_data.columns:\n",
    "        coeff_col = f'{col}_coeff'\n",
    "        if coeff_col in results_df.columns:\n",
    "            coeffs = results_df[coeff_col].dropna()\n",
    "            if len(coeffs) > 0:\n",
    "                print(f\"  {col}: Range=[{coeffs.min():.4f}, {coeffs.max():.4f}], SD={coeffs.std():.4f}\")\n",
    "    \n",
    "    return results_df, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def plot_gwr_results(var_coeffs, states_gdf, figsize=(20, 15)):\n",
    "    \"\"\"\n",
    "    Plot GWR spatial coefficients on continental US map\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    var_coeffs : DataFrame\n",
    "        GWR results with coefficient columns + longitude/latitude\n",
    "    states_gdf : GeoDataFrame  \n",
    "        US state boundaries\n",
    "    figsize : tuple\n",
    "        Figure size\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter for continental US\n",
    "    exclude_states = ['AK', 'HI', 'PR', 'VI', 'GU', 'AS', 'MP']\n",
    "    \n",
    "    # Find state column\n",
    "    state_col = None\n",
    "    for col in ['STUSPS', 'STATE_ABBR', 'NAME', 'STATE']:\n",
    "        if col in states_gdf.columns:\n",
    "            state_col = col\n",
    "            break\n",
    "    \n",
    "    if state_col:\n",
    "        continental_states = states_gdf[~states_gdf[state_col].str.contains('|'.join(exclude_states), na=False)]\n",
    "    else:\n",
    "        continental_states = states_gdf.cx[-130:-65, 20:50]\n",
    "    \n",
    "    # Get variable columns (exclude coordinates)\n",
    "    variables = [col for col in var_coeffs.columns if col not in ['longitude', 'latitude']]\n",
    "    plot_data = var_coeffs.dropna()\n",
    "    \n",
    "    # Set up subplot grid\n",
    "    n_vars = len(variables)\n",
    "    n_cols = 2 if n_vars > 1 else 1\n",
    "    n_rows = (n_vars + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "    if n_vars == 1:\n",
    "        axes = [axes]\n",
    "    elif n_rows == 1:\n",
    "        axes = axes.reshape(1, -1) if n_cols > 1 else [axes]\n",
    "    \n",
    "    fig.suptitle('GWR Spatial Coefficients', fontsize=20, fontweight='bold')\n",
    "    \n",
    "    for i, var in enumerate(variables):\n",
    "        if n_rows > 1:\n",
    "            ax = axes[i // n_cols, i % n_cols]\n",
    "        else:\n",
    "            ax = axes[i % n_cols] if n_cols > 1 else axes[0]\n",
    "        \n",
    "        # Get coefficient data\n",
    "        coeffs = plot_data[var].values\n",
    "        x = plot_data['longitude'].values\n",
    "        y = plot_data['latitude'].values\n",
    "        \n",
    "        # Plot state boundaries\n",
    "        continental_states.boundary.plot(ax=ax, color='black', linewidth=0.5, alpha=0.7)\n",
    "        \n",
    "        # Set map extent\n",
    "        ax.set_xlim(-130, -65)\n",
    "        ax.set_ylim(20, 50)\n",
    "        \n",
    "        # Color normalization (centered at 0)\n",
    "        vmax = np.abs(coeffs).max() if np.abs(coeffs).max() > 0 else 1\n",
    "        norm = TwoSlopeNorm(vmin=-vmax, vcenter=0, vmax=vmax)\n",
    "        \n",
    "        # Scatter plot\n",
    "        scatter = ax.scatter(x, y, c=coeffs, cmap='RdBu', norm=norm, \n",
    "                           s=60, alpha=0.8, edgecolors='black', linewidth=0.5)\n",
    "        \n",
    "        # Formatting\n",
    "        ax.set_title(f'{var}', fontweight='bold', fontsize=14)\n",
    "        ax.set_xlabel('Longitude', fontsize=12)\n",
    "        ax.set_ylabel('Latitude', fontsize=12)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Colorbar\n",
    "        cbar = plt.colorbar(scatter, ax=ax, shrink=0.8)\n",
    "        cbar.set_label('Coefficient', fontsize=10)\n",
    "        \n",
    "        # Simple legend for positive/negative effects\n",
    "        if coeffs.max() > 0 and coeffs.min() < 0:\n",
    "            legend_elements = [\n",
    "                mpatches.Patch(color='darkblue', label='Positive'),\n",
    "                mpatches.Patch(color='darkred', label='Negative')\n",
    "            ]\n",
    "            ax.legend(handles=legend_elements, loc='lower right', fontsize=9)\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    total_subplots = n_rows * n_cols\n",
    "    if n_vars < total_subplots:\n",
    "        for i in range(n_vars, total_subplots):\n",
    "            if n_rows > 1:\n",
    "                ax = axes[i // n_cols, i % n_cols]\n",
    "            else:\n",
    "                ax = axes[i % n_cols] if n_cols > 1 else axes[0]\n",
    "            ax.set_visible(False)\n",
    "    \n",
    "    plt.tight_lat()\n",
    "    return fig\n",
    "\n",
    "# Simple usage:\n",
    "fig = plot_gwr_results(var_coeffs, states_gdf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  3.2 Conduct GWR for geospatial/community characteristics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Prepare coordinates and target variable\n",
    "coords = np.array(valid_hospitals[['long_as', 'lat_as']])\n",
    "y2 = valid_hospitals['ai_base_score'].values\n",
    "    \n",
    "# 2. Prepare feature matrix \n",
    "print(\"Preparing feature matrix...\")\n",
    "X_data2 = pd.DataFrame(index=valid_hospitals.index)\n",
    "    \n",
    "# Hospital characteristics missing value imputation \n",
    "X_data2['svi_themes_median'] = valid_hospitals['svi_themes_median'].fillna(valid_hospitals['svi_themes_median'].median())\n",
    "X_data2['svi_theme1_median'] = valid_hospitals['svi_theme1_median'].fillna(valid_hospitals['svi_theme1_median'].median())\n",
    "X_data2['svi_theme2_median'] = valid_hospitals['svi_theme2_median'].fillna(valid_hospitals['svi_theme2_median'].median())    \n",
    "X_data2['svi_theme3_median'] = valid_hospitals['svi_theme3_median'].fillna(valid_hospitals['svi_theme3_median'].median())\n",
    "X_data2['svi_theme4_median'] = valid_hospitals['svi_theme4_median'].fillna(valid_hospitals['svi_theme4_median'].median())\n",
    "X_data2['national_adi_median'] = valid_hospitals['national_adi_median'].fillna(valid_hospitals['national_adi_median'].median())\n",
    "X_data2['mean_primary_hpss'] = valid_hospitals['mean_primary_hpss'].fillna(0)\n",
    "X_data2['mean_dental_hpss'] = valid_hospitals['mean_dental_hpss'].fillna(0)\n",
    "X_data2['mean_mental_hpss'] = valid_hospitals['mean_mental_hpss'].fillna(0)\n",
    "X_data2['mean_mua_score'] = valid_hospitals['mean_mua_score'].fillna(0)\n",
    "X_data2['mean_mua_elder_score'] = valid_hospitals['mean_mua_score'].fillna(0)\n",
    "X_data2['mean_mua_infant_score'] = valid_hospitals['mean_mua_infant_score'].fillna(0)\n",
    "X_data2['rural_urban_type'] = valid_hospitals['rural_urban_type'].fillna(valid_hospitals['rural_urban_type'].median())\n",
    "X_data2['Device_Percent'] = valid_hospitals['Device_Percent'].fillna(valid_hospitals['Device_Percent'].median())\n",
    "X_data2['Broadband_Percent'] = valid_hospitals['Broadband_Percent'].fillna(valid_hospitals['Broadband_Percent'].median())\n",
    "X_data2['Internet_Percent'] = valid_hospitals['Internet_Percent'].fillna(valid_hospitals['Internet_Percent'].median())\n",
    "    \n",
    "# Standardize continuous variables (except binary variables)\n",
    "continuous_vars = ['svi_themes_median', 'svi_theme1_median', 'svi_theme2_median', 'svi_theme3_median', 'svi_theme4_median', 'national_adi_median', 'Device_Percent', 'Broadband_Percent', 'Internet_Percent', 'mean_primary_hpss', 'mean_dental_hpss', 'mean_mental_hpss', 'mean_mua_score', 'mean_mua_elder_score', 'mean_mua_infant_score', 'rural_urban_type','Device_Percent', 'Broadband_Percent', 'Internet_Percent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "var_coeffs, selected_bandwidth, X_data2 = run_gwr(X_data2, continuous_vars, 2)\n",
    "\n",
    "# Then plot results\n",
    "fig = plot_gwr_results(var_coeffs, states, figsize=(25, 30))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
